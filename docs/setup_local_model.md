# æœ¬åœ°æ¨¡å‹éƒ¨ç½²æŒ‡å— (Advanced)

> **æ³¨æ„**: æœ¬æŒ‡å—é¢å‘å¸Œæœ›ä½¿ç”¨æœ¬åœ°ç¡¬ä»¶è¿è¡Œ Embedding/Rerank æ¨¡å‹çš„é«˜çº§ç”¨æˆ·ã€‚
> é»˜è®¤æƒ…å†µä¸‹ï¼Œ`adaptive-agent-mcp` ä½¿ç”¨ API æä¾›å‘é‡èƒ½åŠ›ï¼Œæ— éœ€ä»»ä½•æœ¬åœ°æ¨¡å‹ã€‚

## é€‚ç”¨åœºæ™¯

é€‰æ‹©æœ¬åœ°æ¨¡å‹çš„ç†ç”±ï¼š
- **éšç§ä¼˜å…ˆ**: æ‰€æœ‰æ•°æ®ç•™åœ¨æœ¬åœ°ï¼Œä¸å‘é€åˆ°ä»»ä½•å¤–éƒ¨ API
- **ç¦»çº¿å¯ç”¨**: æ— ç½‘ç»œç¯å¢ƒä¸‹ä¾ç„¶å¯ç”¨
- **æˆæœ¬èŠ‚çº¦**: æ—  API è°ƒç”¨è´¹ç”¨ï¼ˆå‰ææ˜¯ä½ æœ‰åˆé€‚çš„ç¡¬ä»¶ï¼‰

---

## ğŸ“¦ å®‰è£…ä¾èµ–

### 1. å®‰è£… sentence-transformers

```bash
pip install sentence-transformers
```

> è¿™ä¼šåŒæ—¶å®‰è£… PyTorchã€‚å¦‚æœä½ æœ‰ NVIDIA GPUï¼Œå»ºè®®å…ˆå®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorchï¼š
>
> ```bash
> pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
> ```

### 2. ä¸‹è½½æ¨èæ¨¡å‹

**Embedding æ¨¡å‹** (è¯­ä¹‰ç†è§£):
```python
from sentence_transformers import SentenceTransformer

# æ¨èï¼šè½»é‡çº§é«˜æ•ˆæ¨¡å‹ (~90MB)
model = SentenceTransformer('all-MiniLM-L6-v2')

# æˆ–è€…ï¼šæ›´å¼ºçš„ä¸­æ–‡æ”¯æŒ
model = SentenceTransformer('shibing624/text2vec-base-chinese')
```

**Rerank æ¨¡å‹** (ç²¾æ’):
```python
from sentence_transformers import CrossEncoder

# æ¨èï¼šBGE ç³»åˆ—
reranker = CrossEncoder('BAAI/bge-reranker-base')
```

æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° `~/.cache/huggingface/hub/`ã€‚

---

## é…ç½® adaptive-agent-mcp ä½¿ç”¨æœ¬åœ°æ¨¡å‹

### æ–¹æ¡ˆ Aï¼šä¿®æ”¹ `config.py`

åœ¨ `adaptive_agent_mcp/src/config.py` ä¸­æ·»åŠ ï¼š

```python
class Settings(BaseSettings):
    # ... å…¶ä»–é…ç½® ...
    
    # æœ¬åœ°æ¨¡å‹è®¾ç½®
    use_local_embedding: bool = True
    local_embedding_model: str = "all-MiniLM-L6-v2"
    local_rerank_model: str = "BAAI/bge-reranker-base"
```

### æ–¹æ¡ˆ Bï¼šé€šè¿‡ç¯å¢ƒå˜é‡

```bash
# .env æ–‡ä»¶
ADAPTIVE_USE_LOCAL_EMBEDDING=true
ADAPTIVE_LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2
ADAPTIVE_LOCAL_RERANK_MODEL=BAAI/bge-reranker-base
```

---

## å®ç°æœ¬åœ° VectorClient

åˆ›å»º `adaptive_agent_mcp/src/vector_client_local.py`:

```python
from sentence_transformers import SentenceTransformer, CrossEncoder
from typing import List
import numpy as np

class LocalVectorClient:
    """æœ¬åœ°å‘é‡å®¢æˆ·ç«¯ - ä½¿ç”¨ sentence-transformers"""
    
    def __init__(self, embedding_model: str = "all-MiniLM-L6-v2", 
                 rerank_model: str = "BAAI/bge-reranker-base"):
        self._embed_model = None
        self._rerank_model = None
        self._embedding_model_name = embedding_model
        self._rerank_model_name = rerank_model
    
    @property
    def embed_model(self):
        if self._embed_model is None:
            self._embed_model = SentenceTransformer(self._embedding_model_name)
        return self._embed_model
    
    @property
    def rerank_model(self):
        if self._rerank_model is None:
            self._rerank_model = CrossEncoder(self._rerank_model_name)
        return self._rerank_model
    
    def embed(self, texts: List[str]) -> List[List[float]]:
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡"""
        embeddings = self.embed_model.encode(texts, convert_to_numpy=True)
        return embeddings.tolist()
    
    def rerank(self, query: str, documents: List[str], top_n: int = 10) -> List[dict]:
        """å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº"""
        pairs = [(query, doc) for doc in documents]
        scores = self.rerank_model.predict(pairs)
        
        # æŒ‰åˆ†æ•°é™åºæ’åˆ—
        scored_docs = sorted(
            enumerate(zip(documents, scores)),
            key=lambda x: x[1][1],
            reverse=True
        )[:top_n]
        
        return [
            {"index": idx, "document": doc, "relevance_score": float(score)}
            for idx, (doc, score) in scored_docs
        ]
```

---

## ğŸ§ª æµ‹è¯•æœ¬åœ°æ¨¡å‹

```python
from adaptive_agent_mcp.src.vector_client_local import LocalVectorClient

client = LocalVectorClient()

# æµ‹è¯• Embedding
texts = ["ä»Šå¤©å¤©æ°”å¾ˆå¥½", "æ˜å¤©ä¼šä¸‹é›¨"]
embeddings = client.embed(texts)
print(f"Embedding ç»´åº¦: {len(embeddings[0])}")

# æµ‹è¯• Rerank
query = "å¤©æ°”é¢„æŠ¥"
docs = ["ä»Šå¤©å¤©æ°”å¾ˆå¥½", "æ˜å¤©ä¼šä¸‹é›¨", "æˆ‘å–œæ¬¢åƒè‹¹æœ"]
results = client.rerank(query, docs, top_n=2)
print(f"Rerank ç»“æœ: {results}")
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | æœ¬åœ°æ¨¡å‹ (MiniLM) | API (Qwen3-8B) |
|------|-----------------|----------------|
| å»¶è¿Ÿ | 10-50ms | 200-500ms |
| å†…å­˜å ç”¨ | ~500MB | 0 (è¿œç¨‹) |
| ä¸­æ–‡æ•ˆæœ | ä¸€èˆ¬ | ä¼˜ç§€ |
| ç¦»çº¿å¯ç”¨ | âœ… | âŒ |
| éšç§ | å®Œå…¨æœ¬åœ° | æ•°æ®å‘é€åˆ° API |

---

## â“ å¸¸è§é—®é¢˜

### Q: æ¨¡å‹ä¸‹è½½å¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

ä½¿ç”¨é•œåƒæºï¼š
```bash
export HF_ENDPOINT=https://hf-mirror.com
```

### Q: GPU å†…å­˜ä¸è¶³ï¼Ÿ

ä½¿ç”¨ CPU æ¨¡å¼ï¼š
```python
model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')
```

### Q: å¦‚ä½•é€‰æ‹©æ¨¡å‹ï¼Ÿ

- **é€šç”¨åœºæ™¯**: `all-MiniLM-L6-v2` (å¿«é€Ÿã€è½»é‡)
- **ä¸­æ–‡ä¼˜åŒ–**: `shibing624/text2vec-base-chinese`
- **å¤šè¯­è¨€**: `paraphrase-multilingual-MiniLM-L12-v2`
